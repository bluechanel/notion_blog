---
id: 6e4516ff-0701-4009-9841-b0f023ca43a6
title: ğŸš¢ LLMéƒ¨ç½²(docker+vllm+embedding+rerank) æ”¯æŒå·¥å…·è°ƒç”¨
slug: 6e4516ff-0701-4009-9841-b0f023ca43a6
excerpt: è¯¥æ–‡æ¡£ä»‹ç»äº†å…³äºLLMæ¨¡å‹éƒ¨ç½²çš„å†…å®¹ï¼ŒåŒ…æ‹¬æ¨¡å‹é€‰æ‹©ã€æ¨¡å‹ä¸‹è½½ã€æ¨¡å‹éƒ¨ç½²æ–¹æ¡ˆä»¥åŠæ¨¡å‹ä½¿ç”¨å’ŒåŠ é€Ÿæ–¹æ³•ã€‚æ¨èçš„éƒ¨ç½²æ–¹æ¡ˆæ˜¯ä½¿ç”¨dockeréƒ¨ç½²ï¼ŒåŒæ—¶æä¾›äº†æœ¬åœ°ç¯å¢ƒéƒ¨ç½²çš„æ–¹æ³•ã€‚æ¨¡å‹åŠ é€Ÿæ–¹é¢ä»‹ç»äº†vllmå’Œflash-attentionä¸¤ç§æ–¹æ³•ã€‚embddingæ¨¡å‹ï¼Œrerankæ¨¡å‹
date: 2024-06-03
coverImage: /images/6e4516ff-0701-4009-9841-b0f023ca43a6_7a2d1d060c9fb10000ed4af843e17828.png
lastUpdated: 2025-03-27T07:39:00.000Z
tags: orange:LLM  
---

# æ¨¡å‹é€‰æ‹©


LLMæ¨¡å‹ï¼ŒEmbeddingæ¨¡å‹é€‰æ‹©å‚è€ƒä¸‹é¢çš„æ–‡ç« 


[link_to_page](https://www.notion.so/4ab81ed7-7622-4ef1-9fc6-1e1ae4edbd99)


# æ¨¡å‹ä¸‹è½½


å½“å‰æä¾›æ¨¡å‹çš„ç½‘ç«™ä¸»è¦æœ‰[ModelScope](https://www.modelscope.cn/models)å’Œ[HuggingFace](https://huggingface.co/models)ï¼Œä¸‹è½½æ–¹å¼ä¸»è¦æ˜¯git lfså’Œå¹³å°å°è£…ä¸¤ç§æ–¹æ³•


## ModelScope

1. å®‰è£…modelscope

    ```shell
    pip install modelscope
    ```

2. å¤åˆ¶æ¨¡å‹åç§°

    ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/da864e11-683f-4c2d-a264-16ecdf57fff9/94c1b3e8-aeeb-4fdb-adf5-fedb3bad4f75/image.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=ASIAZI2LB466YJ3NEJPY%2F20250704%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20250704T024333Z&X-Amz-Expires=3600&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEBoaCXVzLXdlc3QtMiJHMEUCIQDurt%2BiA82NUq0gRZkIUCqVVxXAHjoixvG7KDLpVV3a8AIgc41KWdCM99pTxA5TNMRxcwdRZNLrkmBDxdJo%2FQNhxZMq%2FwMIIxAAGgw2Mzc0MjMxODM4MDUiDL9KB6ZHfO3gyUsVQCrcA8Z8Ofz1pdEmratvPBbiXtTH396sX1Zd9%2BVu6SqK9rar6hqWgbFpHBRamBXft8W%2BULfSj%2BstH4XN4tOUs%2FeL3BuTtz%2BjuzErZistRNdp1oCb3cLsO%2FnobFRVwll2968KAaRfcdlXTu7jl9hHBmX2lfN6RP%2FBAzDT4%2FhzebEToe%2FgCMvNhuJJX6SKr0FiuD7uWqpZGR2Ohq45hYYkumpzCiMdWhV98auqfI3m86DJOLn6914q1OovHxMXQNB49veYhec2g72haA5laJCz39e4X62%2BWWT9%2FcQZNrEZAvlLnIhTI%2BGgRNff6Mqs625k3kqN0iOCogUJQtVJXtbjV7iuFWknMufFF6ISDhaDoHkLIB9MjPVm9Hw4weUpy7sbqLtT5sDiuMk5BuTpassGLmdbrHfd8%2BPqaMS6JId7OTA0ac6l7asse0X721IVcDAAZ0BiNRA2rXigdMbzje5IJ%2BGvRYn6eq4SQZh5cArB15H2BTduOCIzaQHUeMcqRxtbftpjmyciZHaP%2FOBapZvc7ahaRyLQG6pF7oFOGIXqT8iEllYNcQgsTjn%2BQ9yqa6s33vNn9tUclW4PaK%2FRCabX9Vh6alxNy19C8nKcWceF84h%2B2H8zmKYw9aIqAqDXpKb9MOjlnMMGOqUBedtfVHiqwWxjc3CHIQz26ma1WrxxrWClboHx%2Fm9fxNZHdoC88eYz0m9OWbpv9%2FLaaps8dcpC2177WkD5QsYkWrgrxfgJg2GkeR9lKF9aKE4jNpdqjU68eYKtUWr3Fvq%2B96NrkQRlwcDJUJWd4p%2B%2Ff6IgjJk7sphkOrvyk8WJP9gD0EpCXp%2B9pO0%2Fgqup%2BqIecNeqvMQ51pInrvP5Mm%2Bmm0L%2F6m0a&X-Amz-Signature=52630433f5758e2f7ddffc12a41728a80d5754022f42be952c685a981ebf44d1&X-Amz-SignedHeaders=host&x-amz-checksum-mode=ENABLED&x-id=GetObject)

3. ä¸‹è½½æ¨¡å‹åˆ°æŒ‡å®šç›®å½•

    ```shell
    #æ¨¡å‹ä¸‹è½½
    from modelscope import snapshot_download
    # æ³¨æ„æ›¿æ¢æ¨¡å‹åç§°ï¼Œä¸æŒ‡å®šç›®å½•ï¼Œåˆ™é»˜è®¤ä¸‹è½½åˆ°ç”¨æˆ·ç›®å½•.cache/modelscope/
    model_dir = snapshot_download('qwen/Qwen2.5-72B-Instruct-GPTQ-Int8', cache_dir='/data/models/')
    ```


# æ¨¡å‹éƒ¨ç½²


## LLMã€Embeddingã€Rerank dockeréƒ¨ç½²

1. å®‰è£…dockerï¼Œå›½å†…ä½¿ç”¨[æ¸…åå¼€æºè½¯ä»¶é•œåƒç«™](https://mirror.tuna.tsinghua.edu.cn/help/docker-ce/)
2. [å®‰è£…](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html)[**NVIDIA Container Toolkit**](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html)
3. ä½¿ç”¨docker compose éƒ¨ç½²ï¼Œéƒ¨ç½²æ–‡ä»¶è§ä¸‹é¢çš„githubåœ°å€

    [bookmark](https://github.com/bluechanel/deploy_llm/tree/main)

4. clone é¡¹ç›®

    ```json
    git clone git@github.com:bluechanel/deploy_llm.git
    cd deploy_llm
    ```

5. ä¿®æ”¹æ¨¡å‹ä¿å­˜ç›®å½•

    ```yaml
    x-vllm-common:
      &common
      image: vllm/vllm-openai:latest
      restart: unless-stopped
      environment:
        TZ: "Asia/Shanghai"
      volumes:
        - /data/models:/models # æ­¤å¤„ä¿®æ”¹ä¸ºå®é™…æ¨¡å‹ç›®å½•ã€‚
      networks:
        - vllm
    ```

6. ä¿®æ”¹æ¨¡å‹å¯åŠ¨å‚æ•°

    vllmçš„æ›´å¤šå‚æ•°è§[vllmæ–‡æ¡£](https://docs.vllm.ai/en/stable/serving/openai_compatible_server.html#cli-reference)

    1. LLM

        ä¿®æ”¹command é‡Œé¢çš„ `â€”-model` åé¢çš„æ¨¡å‹ç›®å½•ï¼Œæ˜ å°„åˆ°dockerä¸­çš„ç›®å½•


        ```yaml
        command: [ "--model","/models/{ä½ çš„æ¨¡å‹ç›®å½•}",  "--enable-prefix-caching","--host", "0.0.0.0", "--port", "8000", "--served-model-name", "gpt-4", "--distributed-executor-backend","ray","--tensor-parallel-size","2","--pipeline-parallel-size", "1","--enable-reasoning","--reasoning-parser","deepseek_r1"]
        ```


        è¿™é‡Œæœ‰å‡ ä¸ªå¸¸ç”¨å‚æ•°è¯´æ˜


        `--served-model-name`ï¼šæ¨¡å‹è°ƒç”¨åç§°ï¼Œå¯ä»¥è‡ªå®šä¹‰å¡«å†™ä»»æ„åç§°


        `--tensor-parallel-size`ï¼šå¹¶è¡Œæ•°é‡ï¼Œå–å†³äºä½¿ç”¨çš„æ˜¾å¡æ•°é‡
        `--enable-prefix-caching`ï¼šå¼€å¯å‰ç¼€ç¼“å­˜ï¼Œå¯¹å¤šè½®å¯¹è¯æœ‰ä¸€å®šæ•ˆç‡æå‡


        `"--enable-reasoning", "--reasoning-parser","deepseek_r1"` å¦‚æœæ˜¯æ¨ç†æ¨¡å‹ï¼Œå¯ä»¥é…ç½®è¯¥å‚æ•°ï¼Œç›®å‰æ”¯æŒ`deepseek_r1`ç³»åˆ—


        `"--enable-auto-tool-choice", "--tool-call-parser", "hermesâ€`ï¼šå¼€å¯å·¥å…·è°ƒç”¨èƒ½åŠ›ï¼Œä¾‹å¦‚Qwen2.5 ç³»åˆ—æ¨¡å‹ï¼Œå‚è€ƒ


        ```yaml
        command: [ "--model","/models/qwen/Qwen2___5-72B-Instruct-GPTQ-Int8", "--enable-prefix-caching", "--host", "0.0.0.0", "--port", "8000", "--served-model-name", "gpt-4", "--enable-auto-tool-choice", "--tool-call-parser", "hermes","--distributed-executor-backend","ray","--tensor-parallel-size","2","--pipeline-parallel-size", "1" ]
        ```

    2. Embedding

        ä¿®æ”¹command é‡Œé¢çš„ `â€”-model` åé¢çš„æ¨¡å‹ç›®å½•ä¸ºæ˜ å°„åˆ°dockerä¸­çš„embeddingæ¨¡å‹ç›®å½•


        ```yaml
        command: [ "--model","/models/{ä½ çš„æ¨¡å‹ç›®å½•}",  "--host", "0.0.0.0", "--port", "8000", "--task", "embed", "--served-model-name", "gte-large-zh"]
        ```

    3. Rerank

        ä¿®æ”¹command é‡Œé¢çš„ `â€”-model` åé¢çš„æ¨¡å‹ç›®å½•ä¸ºæ˜ å°„åˆ°dockerä¸­çš„rerankeræ¨¡å‹ç›®å½•


        ```yaml
        command: [ "--model","/models/{ä½ çš„æ¨¡å‹ç›®å½•}",  "--host", "0.0.0.0", "--port", "8000", "--task", "score", "--served-model-name", "bge-reranker-base"]
        ```

7. ä½¿ç”¨docker compose å¯åŠ¨æ¨¡å‹

    ```json
    docker compose up -d
    ```


    æ¨¡å‹å¯åŠ¨åï¼Œdockerå¯¹å¤–æš´éœ²åœ¨8000ç«¯å£ï¼Œè®¿é—®`http://ip:8000/docs`æŸ¥çœ‹æ¥å£æ–‡æ¡£

8. æµ‹è¯•ï¼Œä½¿ç”¨demoè„šæœ¬æµ‹è¯•ã€‚æ³¨æ„ä¿®æ”¹ å„æ¨¡å‹çš„è‡ªå®šä¹‰åç§°

    ```json
    python demo.py
    ```


## LLMã€embeddingã€rerankeråˆ†ä½“éƒ¨ç½²

# LLMéƒ¨ç½²

1. clone é¡¹ç›®ï¼Œå¹¶è¿›å…¥llmç›®å½•

    ```shell
    git clone https://github.com/bluechanel/deploy_llm.git
    cd deploy_llm/llm
    ```

2. ä¿®æ”¹æ¨¡å‹æ˜ å°„è·¯å¾„ï¼Œ`vim docker-compose.yaml`

    ```shell
    x-common:
      &common
      volumes:
      # ä¿®æ”¹ä¸ºè‡ªå·±ä¸‹è½½æ¨¡å‹çš„åœ°å€æ˜ å°„åˆ°å®¹å™¨/models
        - 
    /data/models:/models
    
      environment:
      # æ—¶åŒºè®¾ç½®
        &common-env
        TZ: "Asia/Shanghai"
    ```


    ä¿®æ”¹æ¨¡å‹å¯åŠ¨å‘½ä»¤ï¼Œåœ¨vllmæœåŠ¡ä¸­ï¼Œä¿®æ”¹`--served-model-name` ä¸ºè‡ªå®šä¹‰æ¨¡å‹åç§°   `--model`ä¸ºä¿®æ”¹åçš„æ¨¡å‹è·¯å¾„ï¼Œ`--tensor-parallel-size 4`ä¸ºä½¿ç”¨æ˜¾å¡æ•°é‡ï¼Œæ ¹æ®å®é™…æƒ…å†µä¿®æ”¹


    ```shell
    command: [ "--model","/models/qwen/Qwen2___5-72B-Instruct-GPTQ-Int8",  "--host", "0.0.0.0", "--port", "8000", "--served-model-name", "gpt-4", "--enable-auto-tool-choice", "--tool-call-parser", "hermes","--distributed-executor-backend","ray","--tensor-parallel-size","4","--pipeline-parallel-size", "1" ]
    ```

3. å¯åŠ¨`docker compose up -d`
4. æŸ¥çœ‹apiæ–‡æ¡£`http://ip:1281/docs`

## Embedding+Rerankéƒ¨ç½²


> ğŸ’¡ embedding å’Œ rerankæ˜¯ä¸¤ä¸ªæ¨¡å‹ï¼Œå¯ç›´æ¥åœ¨modelscopeæœç´¢rerankæ‰¾ç›¸å…³æ¨¡å‹

1. è¿›å…¥embeddingç›®å½•
2. ä¿®æ”¹æ¨¡å‹æ˜ å°„è·¯å¾„ï¼Œ`vim docker-compose.yaml`

    ```shell
    x-common:
      &common
      volumes:
      # ä¿®æ”¹ä¸ºè‡ªå·±ä¸‹è½½æ¨¡å‹çš„åœ°å€æ˜ å°„åˆ°å®¹å™¨/models
        - 
    /data/models:/models
    
      environment:
      # æ—¶åŒºè®¾ç½®
        &common-env
        TZ: "Asia/Shanghai"
    ```


    ä¿®æ”¹embeddingå¯åŠ¨å‘½ä»¤ï¼Œä¿®æ”¹`--model-id`ä¸ºä¿®æ”¹åçš„æ¨¡å‹è·¯å¾„


    ```shell
    command: [ "--json-output", "--model-id", "/models/maple77/gte-large-zh"]
    ```

3. å¯åŠ¨`docker compose up -d`
4. æŸ¥çœ‹apiæ–‡æ¡£embedding: `http://ip:1282/docs` rerank:`http://ip:1283/docs`

    ![Untitled.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/da864e11-683f-4c2d-a264-16ecdf57fff9/e1756aaa-6b65-4e54-a5fe-aa2bba18033b/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=ASIAZI2LB466SOLGJIOX%2F20250704%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20250704T024342Z&X-Amz-Expires=3600&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEBoaCXVzLXdlc3QtMiJHMEUCID9neLRzLaOc4fBu7AfmUTHC3wrvJ1sbsU4TivnJX%2BHiAiEAh%2BRC%2FlHFlDrtpZLQCdxc78yWwg%2FzjMp4JtvRBztSDbQq%2FwMIIxAAGgw2Mzc0MjMxODM4MDUiDFqRBg%2BmDC5OHqRkHyrcAzIyiLEd7NiwdIUqdaMPVWLSMAZ8%2BYecthi0I8fFyDC8R8CMgHvRAxLG8Ug0Sm1HCiR%2F57w7h9RvZG%2FWQIMmI16amTK1lROOvqkyeAfqcjiLfoOrsN%2FFAgvbkyLDn8YF9In1Nn5U4nDsmkBgYMzTzfnQZshoxxPyA6V%2F%2BQQCub%2BaLem165%2FpmdlBFEWRCpI2ssw4r3Trdpi2S6yceFZYNRTRUdStVBQsssxYNzVhupMRJJsXFpFnKPUPibsUY31CBfQRSQb2FjGc9lWBI%2Bj1cgXLfydM3PX%2B%2FiD6x73uLcYRiyp2Lf58dY0dDNDDKwc6Y6H43y%2BB7ZIo7Pc%2FtaaitRd%2BS2GTA%2FHPuyVTLYZ6tbpXo0OZIHJ%2FT801vXReSFRdkPF4tzr8b%2FT5yRhgEwtI6NLnNRRRgMe7zeGnxDXKMDuzQ%2F6AmhEl%2B115ngxMyNG7SW9InGrpGFgk0ls5AGjIhe1wsXMaXaJtkIZeZDdHkQoFbt9TndTwS7eu%2BN78c51dCNZybOd8AMWccijf3Gao3wIYUB2YwMOOmbUfgMmQi7EAMQH49kGLPlEpXJ7OzoSLRl4OBnnCu%2FrloNkv2Rgu6%2BLtuARFWaQV2bSTnamh2qUyxPavw0q5TMAYVb4nMOflnMMGOqUB5cL5bg1ZSfWaIXWdBAyxNUZW%2B0v3AITKlxRWMFq7CmYd5eL8bDWchVzMr3y%2BtzDC8d7UfP8a4w7Fo25P0%2FYIKsWAMjKUcHZJyh0FFnvZ2WWpYEYWZlXOLQ4sli9t1LLBmPLO8kPxDrguXSJxAws3x7w42PNDljhQEjUByUrstohO8Iti%2FxL3I8hS0DYZJd3uOYU93iFNYWdPcPM5NCDZNc4%2BE6au&X-Amz-Signature=d05486d2dc0b5176df34b5cf0eb1c473089b742e3ad83b2b6b8a1a88abd9a774&X-Amz-SignedHeaders=host&x-amz-checksum-mode=ENABLED&x-id=GetObject)


**æ’é”™**


vllmå¯åŠ¨å¯èƒ½ä¼šæœ‰å¦‚ä¸‹æŠ¥é”™ï¼Œåœ¨docker composeä¸­ä¿®æ”¹`shm_size`çš„å€¼ä¸ºé”™è¯¯æç¤ºçš„å€¼ï¼Œå³å¯


![Untitled.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/da864e11-683f-4c2d-a264-16ecdf57fff9/bae86682-7725-440f-a248-074de305b696/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=ASIAZI2LB466UFMGBFWZ%2F20250704%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20250704T024340Z&X-Amz-Expires=3600&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEBoaCXVzLXdlc3QtMiJGMEQCIF1LAv9i799K7zS4je%2B4TvbuD1o50fRMFipy2z7XfUAmAiAKMAPStgaAfDxfr4rR0ZZaVqs%2BBeBHxt0rtxUrWnGNGyr%2FAwgjEAAaDDYzNzQyMzE4MzgwNSIM8%2BlcGTgjW9ysy%2B7wKtwDo46kHDdEZ0pJDTEUThqWeAPdRuemdV4xXjHwlD7pb6yJ%2F0JR%2F7UgG9s8pxjJF%2BfYjmY2VB5aECsSGvY3SzIpJ8IGXdnfr8czCNgHP14ZWb2qXmb8MM7fHmk4RB5iXx8bRdRnrDJwOIGpwFg%2FSf%2FJ9HiIzl%2BdyNhLmB3X4TO7HRshlG8MrtHJSsykytKUBMAIGDWVVwXzYfW4e8PXnhJ9Uwklbkjn6rE9Aqd%2Bgdw0NUuJhA5esbM1ZN7P1htlH4vkcdXF4kpl0ubp%2Fef%2B%2BMZr0CBvzhbJmlzz32p%2BwvzenwA5vaX1BhedcgS38x6ZX4C074ewwsBfsKB%2B1mQ%2FgaySmw%2BDxDhLcGfsQucUoMwSfF0v%2FiJN5Vjj3j2X48B6mYQWZlZCsUeQN9%2BvwDZZZ%2FK%2Fx1C9P%2Fxgiz19aV9R%2FhBGqe27Xh1qzt%2FHmkgaPqGNgTYhBVFyMOrz56Sp%2BMnMfd4RpZcnqiWs3J7v9M8KbgqR%2FzIQAZqR8R09dhvFq7n%2FGIcvocrF%2FYiX0ARX4MFAHfY66ODXS41v7BZr8HBq6uyHAFWDXF%2FdHWXa6RxHLdjHo26S8aRDGzpdR2o3M4MB77GPloXDxCWZCPtVRpTmiCaloJz%2FZt3v0%2FtDXfHo85kw%2F%2BWcwwY6pgFm3lwp4Cf8czDLnY8yk%2FmP9U0UWKykyGT%2FGLEGVf%2Bn1ioBCjfj14Daq0waNlReetG4VtgbSzZJlXSo%2BlEqTt8fQgCTUOQAF79uoia5FM3Gfcd2KN41gXKBf2seXRdHLPUD%2Fbu8i%2FuzMvE%2Fuc3VL6LSqi8pfzjxtgJ5ic4AKsGGjgcM6CAqaFxCk%2BK6XS%2FvWPLAZQxfbci7vJ2r4DF9SwylSITFdEFV&X-Amz-Signature=dd7a88409d13ca63d2ee14108d4af5f35cd92c66af5d0d0d7b32a70db8ba9164&X-Amz-SignedHeaders=host&x-amz-checksum-mode=ENABLED&x-id=GetObject)


## å·²åºŸå¼ƒéƒ¨ç½²æ–¹æ³•ï¼ˆ20240918ï¼‰

# æ¨¡å‹éƒ¨ç½²


å½“å‰å¼€æºçš„æ¨¡å‹éƒ¨ç½²æœåŠ¡å¾ˆå¤šï¼Œä¸»æµçš„æœ‰[FastChatã€](https://github.com/lm-sys/FastChat)[Xinference](https://github.com/xorbitsai/inference)ã€[ollama](https://github.com/ollama/ollama)ã€[vllm](https://github.com/vllm-project/vllm)ã€[lightllm](https://github.com/ModelTC/lightllm)ï¼Œå…¶ä¸­vllmï¼Œlightllmä¸»è¦æ˜¯ç”¨äº**æ¨¡å‹åŠ é€Ÿ**ã€‚åŒæ—¶FastChatç­‰ä¹Ÿæ”¯æŒä½¿ç”¨vllmå¯åŠ¨æ¨¡å‹è·å¾—é«˜æ•ˆåŠ é€Ÿï¼Œä¸è¿‡è¿™äº›éƒ¨ç½²æœåŠ¡éƒ½**ä¸æ”¯æŒå·¥å…·è°ƒç”¨**ï¼Œä¹Ÿå°±æ˜¯OpenAI æ¥å£çš„toolså‚æ•°ã€‚é‚æˆ‘å¯¹FastChatçš„ä»£ç åšäº†éƒ¨åˆ†ä¿®æ”¹ï¼Œä½¿å…¶**æ”¯æŒtoolså‚æ•°ã€‚**å…·ä½“ä»£ç è§githubï¼Œï¼ˆä»…æµ‹è¯•äº†Qwenç³»åˆ—ï¼‰


> ğŸ’¡ ç”±äºä¸åŒæ¨¡å‹è®­ç»ƒæ•°æ®ä¸åŒï¼ŒåŒæ ·çš„Promptåœ¨ä¸åŒçš„æ¨¡å‹ä¸­ç»“æœå·®å¼‚è¾ƒå¤§ï¼Œå¯¼è‡´toolsèƒ½åŠ›ä¸ç¨³å®šï¼Œè¯¥èƒ½åŠ›æœªæäº¤FastChatåŸå§‹ä»“åº“ã€‚


[bookmark](https://github.com/bluechanel/FastChat/tree/main)


æ¨èçš„éƒ¨ç½²æ–¹æ¡ˆä¸ºï¼šFastChat+vllm


## æ–¹æ¡ˆ1ï¼šdockeréƒ¨ç½²(æ¨è)

1. å®‰è£…dockerï¼Œå›½å†…ä½¿ç”¨[æ¸…åå¼€æºè½¯ä»¶é•œåƒç«™](https://mirror.tuna.tsinghua.edu.cn/help/docker-ce/)
2. [å®‰è£…](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html)[**NVIDIA Container Toolkit**](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html)
3. ä½¿ç”¨docker compose éƒ¨ç½²ï¼Œéƒ¨ç½²æ–‡ä»¶è§ä¸‹é¢çš„githubåœ°å€

    [bookmark](https://github.com/bluechanel/deploy_llm/tree/main)


### LLMéƒ¨ç½²

1. clone é¡¹ç›®ï¼Œå¹¶è¿›å…¥llmç›®å½•

    ```shell
    git clone https://github.com/bluechanel/deploy_llm.git
    cd deploy_llm/llm
    ```

2. ä¿®æ”¹æ¨¡å‹æ˜ å°„è·¯å¾„ï¼Œ`vim docker-compose.yaml`

    ```shell
    x-common:
      &common
      volumes:
      # ä¿®æ”¹ä¸ºè‡ªå·±ä¸‹è½½æ¨¡å‹çš„åœ°å€æ˜ å°„åˆ°å®¹å™¨/models
        - 
    /data/models:/models
    
      environment:
      # æ—¶åŒºè®¾ç½®
        &common-env
        TZ: "Asia/Shanghai"
    ```


    ä¿®æ”¹æ¨¡å‹å¯åŠ¨å‘½ä»¤ï¼Œåœ¨`fastchat-model-worker`æœåŠ¡ä¸­ï¼Œä¿®æ”¹`--model-names` ä¸ºè‡ªå®šä¹‰æ¨¡å‹åç§°   `--model-path`ä¸ºä¿®æ”¹åçš„æ¨¡å‹è·¯å¾„ï¼Œ`"--num-gpus", "4"`ä¸ºä½¿ç”¨æ˜¾å¡æ•°é‡ï¼Œæ ¹æ®å®é™…æƒ…å†µä¿®æ”¹


    ```shell
    entrypoint: [ "python3", "-m", "fastchat.serve.vllm_worker", "--model-names", "gpt-4", "--model-path", "/models/qwen/Qwen2-72B-Instruct-GPTQ-Int8", "--worker-address", "http://fastchat-model-worker:21002", "--controller-address", "http://fastchat-controller:21001", "--host", "0.0.0.0", "--port", "21002", "--num-gpus", "4" ]
    ```

3. å¯åŠ¨`docker compose up -d`

    **æ³¨æ„:**


    æ­¤ç‰ˆæœ¬Apiæ¥å£ä½¿ç”¨çš„æ˜¯æ”¯æŒ**å·¥å…·è°ƒç”¨**çš„ï¼Œå¦‚æœä¸éœ€è¦ï¼Œè¯·ä¿®æ”¹`docker-compose.yaml`æ–‡ä»¶ä¸­`fastchat-api-server`çš„å¯åŠ¨å‘½ä»¤ä¸º


    ```shell
    entrypoint: [ "python3", "-m", "fastchat.serve.openai_api_server", "--controller-address", "http://fastchat-controller:21001", "--host", "0.0.0.0", "--port", "8000" ]
    ```

4. æŸ¥çœ‹apiæ–‡æ¡£`http://ip:1281/docs`

    ![Untitled.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/da864e11-683f-4c2d-a264-16ecdf57fff9/5813f5f8-9f74-497d-a7d3-ff6317a1e549/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=ASIAZI2LB4667AMUC7NV%2F20250704%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20250704T024346Z&X-Amz-Expires=3600&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEBoaCXVzLXdlc3QtMiJHMEUCIDLveyDu4mmU05r3Bw7NPFzXh0teziZtOKPXBQBxPBVLAiEAscClpJu3VPt8LgmnJcE4yomZBDQB611GDBgQ6xFaG%2FUq%2FwMIIxAAGgw2Mzc0MjMxODM4MDUiDLjONnEq%2BeRev%2FoW1CrcA8S68bfomltoNNDXMbvrM5OWQJlk06AI6MaXEXpm78M36JENTLuiGoVoUW8ebVHAOGUeNhq7e%2BrVk3pfi3PBeFeWkHfYpgwlbDhxl1rQMBRJw%2F1S%2F8DMxQljJh94sIYIT4NdqZaxAb%2FYCd%2B4EmRzwfLrMwCQCuOaSQYydswpLFfs2%2BAu0ToDvTzWWhsvXJ1rCd1mnswA49SmbSZvUd%2FRJ79LIeqHvt8%2FF7MK%2B6WcnzpkYWi0J%2BpIdxO8Y5pIL1RGr6k5fGzFeHleJvshF%2FYZv6P6qZ4w0KJYdZfrLNp2ISwOshYMLf7638gigXyYg8rv%2By3%2BqcyunmuyMWqYtSgfB1m8PjAOvfLtmkm89uGjAptbU3QitRRfnyuPT97PYpvmyD9gsG8rsxQTQ1pQOegYGyovSqztEmQM5i2ias2Miv5SYHcb4BJ3oTtuLWFKb289mK%2FOwC14wp2mSTlhrJvEnt3x%2BM%2B0Mzkysgl6lOfk%2FOzANRP1043%2FlyYvcO3RFro5xtIWRnrWLGor4upkNL9ewjn6Dhr2fdpaOB6Up6gRf%2F1nyRUn4B1flZNpObZmtu7F4wco3m0YHhffZ%2BIN%2FGlNftRad5ILS3LT6gHO%2Fp1ejGtH%2FNq7Y9QescSQ9Zl2MJTknMMGOqUBe8RCSqKXzQJM%2F%2F6eg7SdPg%2FNdgMmbXVTDGa1OajlAVQduVFQh46DjZLz8akGqSTG1HycH32chIlTid9OQyGo8IKTz8j0%2FQSLC95NDnHRfOe3vCN%2BWJO9V4snipLqsK4g7OOU9mua9FfsBQgE9HcWG%2BTXbaS8X5VzwGPNA5s5HlX7fEhD%2FyEnWzfgKBozpe4tcWVsBUwizi4nmBMzKfJc3fIaPPhl&X-Amz-Signature=37781ed5fcc193487065ad77ab87cc8ac0b99a48c807d99662a0cf50bbd45075&X-Amz-SignedHeaders=host&x-amz-checksum-mode=ENABLED&x-id=GetObject)


## æ–¹æ¡ˆ2ï¼šæœ¬åœ°ç¯å¢ƒéƒ¨ç½²


ä½¿ç”¨fastchatåŠ è½½æ¨¡å‹ï¼ˆ[æ”¯æŒæ¨¡å‹](https://github.com/lm-sys/FastChat/blob/main/docs/model_support.md)ï¼‰ï¼Œç”±äºLLMéƒ½æ˜¯ç”±transformerså¼€å‘ï¼Œç†è®ºä¸Šfschatå¯ä»¥ç”¨äºå¯åŠ¨æ‰€æœ‰LLM


[link_preview](https://github.com/lm-sys/FastChat)


```python
conda create -n fschat python=3.10

pip install fschat
```


å‘½ä»¤è¡Œå¯åŠ¨


```python
conda activate fschat
python -m fastchat.serve.cli --model-path /data/models/qwen/Qwen-14B-Chat
```


openaiæ¥å£æ–¹å¼å¯åŠ¨


```python
conda activate fschat
python -m fastchat.serve.controller
python -m fastchat.serve.model_worker --model-path /data/models/qwen/Qwen-14B-Chat
# æ­¤å¤„ä¹Ÿå¯æ›¿æ¢ä¸ºä½¿ç”¨vllm worker
# python -m fastchat.serve.vllm_worker --model-path /data/models/qwen/Qwen-14B-Chat
python -m fastchat.serve.openai_api_server --host 0.0.0.0 --port 1282
```


### supervisor ç®¡ç†


```python
# ç”±äºå¯åŠ¨é¡¹è¾ƒå¤šï¼Œæˆ‘ä»¬ä½¿ç”¨supervisorç®¡ç†
pip install supervisor
```


supervisor é…ç½®æ–‡ä»¶`supervisord.conf`å¢åŠ å¦‚ä¸‹å†…å®¹ï¼Œå¹¶åˆ›å»ºæ–‡ä»¶å¤¹`/data/supervisor/conf.d`


```python
[include]
files = /data/supervisor/conf.d/*.conf
```


åœ¨`/data/supervisor/conf.d`ä¸­åˆ›å»º`llm.conf`,å†™å…¥å¦‚ä¸‹å†…å®¹, é‡ç‚¹æ˜¯llm_modelçš„å¯åŠ¨å‚æ•°ï¼Œmodel_pathç”¨äºæŒ‡å®šæ¨¡å‹æ–‡ä»¶çš„åœ°å€ï¼Œå¯¹äºå¤šGPUï¼Œæ·»åŠ å‚æ•°`--num-gpus 4 --max-gpu-memory "80GiB"`


```python
[program:llm_ctrl]
command=/home/jx/anaconda3/envs/fschat/bin/python3 -m fastchat.serve.controller
stdout_logfile=/data/supervisor/logs/ctrl.log

[program:llm_model]
command=/home/jx/anaconda3/envs/fschat/bin/python3 -m fastchat.serve.model_worker --model-path /data/models/qwen/Qwen-14B-Chat --num-gpus 4 --max-gpu-memory "80GiB"
stdout_logfile=/data/supervisor/logs/model.log

[program:llm_api]
command=/home/jx/anaconda3/envs/fschat/bin/python3 -m fastchat.serve.openai_api_server --host 0.0.0.0 --port 1282
stdout_logfile=/data/supervisor/logs/api.log
```


# æ¨¡å‹ä½¿ç”¨


åœ¨langchianä¸­å¥—å£³ChatOpenAIä½¿ç”¨ï¼Œæˆ–ç›´æ¥ä½¿ç”¨OpenAI SDKï¼Œå¯å‚è€ƒdemo.py


### LLM


**æ–¹å¼1**


```shell
from langchain_openai import ChatOpenAI
from langchain_core.pydantic_v1 import SecretStr

class MyChat(ChatOpenAI):
    openai_api_base = "http://ip:1282/v1"
    openai_api_key = SecretStr("123456")
    model_name = "Qwen-14B-Chat"
    max_tokens = 1024# ä¾æ®ä¸åŒæ¨¡å‹æ”¯æŒçš„é•¿åº¦è¿›è¡Œè°ƒæ•´

llm=MyChat(temperature=0)
```


**æ–¹å¼2**


```python
os.environ.setdefault("OPENAI_API_KEY", "12123123")
os.environ.setdefault("OPENAI_API_BASE", "http://ip:1282/v1")
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(model_name="Qwen-14B-Chat")
```


### Embedding


```shell
from langchain_openai import OpenAIEmbeddings
from pydantic.v1 import SecretStr


class TaliAPIEmbeddings(OpenAIEmbeddings):
    openai_api_base = "http://ip:1281/v1"
    openai_api_key = SecretStr("123456")
    check_embedding_ctx_length = False
```


# æ¨¡å‹åŠ é€Ÿ

1. [vllm](https://github.com/vllm-project/vllm)
2. [flash-attention](https://github.com/Dao-AILab/flash-attention)

    å®‰è£…é‡åˆ°çš„é—®é¢˜ï¼š

    1. OSError: CUDA_HOME environment variable is not set. Please set it to your CUDA install root.

        æŒ‡å®šcuda homeåœ°å€


        `CUDA_HOME=/usr/local/cuda-11.8 python` [`setup.py`](http://setup.py/) `install`or`CUDA_HOME=/usr/local/cuda-11.8 pip install flash-attn --no-build-isolation`

